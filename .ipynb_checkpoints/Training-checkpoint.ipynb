{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15b302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aasth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [308/308 42:35, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 1: Imports and Setup\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer, pipeline, DataCollatorForLanguageModeling\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Ensure the save directory exists for the model\n",
    "model_save_dir = \"./model\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Part 2: Data Preparation\n",
    "data_path = r\"C:\\Users\\aasth\\OneDrive\\Desktop\\LLM_Mental_Health_Support_Chatbot\\Dataset\\mental_health_conversational_dataset_train.csv\"  # Update this path to your dataset\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "def preprocess_text(row):\n",
    "    parts = row.split(\"<<<ASSISTANT>>>:\")\n",
    "    question = parts[0].replace(\"<<<HUMAN>>>:\", \"\").strip().lower()\n",
    "    answer = parts[1].strip().lower() if len(parts) > 1 else \"\"\n",
    "    return f\"{question} {answer}\"\n",
    "\n",
    "data['processed_text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Part 3: Tokenization and Dataset Preparation\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "inputs = tokenizer(data['processed_text'].tolist(), truncation=True, max_length=512, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "class MentalHealthDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = item['input_ids'].clone()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "dataset = MentalHealthDataset(inputs)\n",
    "\n",
    "# Part 4: Model Training\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_dir,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=2,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(model_save_dir)\n",
    "tokenizer.save_pretrained(model_save_dir)\n",
    "\n",
    "# Function to Trim Generated Text to Last Complete Sentence\n",
    "def trim_to_last_sentence(text):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    if sentences and not text.endswith(('.', '?', '!')):\n",
    "        sentences = sentences[:-1]\n",
    "    return ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc70a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Mental Health Support Chatbot. Type 'quit' to exit.\n",
      "You: what is mental illness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: what is mental illness? mental health disorders are characterized by problems in the body and brain causing changes in function that may include:\n",
      "1. disturbances in memory or thinking. 2. abnormalities in concentration and memory. 3. dysfunction in social behaviors or emotional patterns.\n",
      "4. hyperactivity. 5. abnormal mood swings. 6. hypnotherapy. 7. alcohol abuse. 8. insomnia. 9. seizures\n",
      "10. eating disorders \n",
      "11. obesity. 12. mental illnesses like schizophrenia, bipolar disorder, anxiety disorder that are complex by nature, or schizophrenia that involve mental symptoms that take time to develop, such as hallucinations of dreams (seeing or hearing voices), hallucinations or delusions of physical pain, suicidal thoughts or flashbacks.\n",
      "\n",
      "Feedback on the advice: 5\n",
      "Feedback sentiment: POSITIVE\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "# Part 5: Loading Model and Tokenizer for Interaction\n",
    "def load_model_and_tokenizer(model_dir):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
    "    chatbot = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "    return chatbot\n",
    "\n",
    "# Initialize Sentiment Analysis Pipeline\n",
    "sentiment_model = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Interactive Chat Function with Sentence Completion Handling\n",
    "def chat_with_sentiment_analysis(chatbot):\n",
    "    print(\"Welcome to the Mental Health Support Chatbot. Type 'quit' to exit.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        generated_responses = chatbot(user_input, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "        response = generated_responses[0]['generated_text']\n",
    "        response_trimmed = trim_to_last_sentence(response)\n",
    "        print(f\"Assistant: {response_trimmed}\\n\")\n",
    "        feedback = input(\"Feedback on the advice: \")\n",
    "        sentiment_result = sentiment_model(feedback)\n",
    "        sentiment = sentiment_result[0]['label']\n",
    "        print(f\"Feedback sentiment: {sentiment}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_dir = \"./model\"  # Ensure this points to the directory where your model is saved\n",
    "    chatbot = load_model_and_tokenizer(model_dir)\n",
    "    chat_with_sentiment_analysis(chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74042f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
